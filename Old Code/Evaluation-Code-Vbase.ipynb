{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Evaluation Code\n",
    "\n",
    "This notebook will be very __similar__ to the code I use to evaluate your results - it is provided for __your convenience__ so that you can use it to evaluate your preprocessing results at any time before your __final submission__.\n",
    "\n",
    "Please note that the results here will __NOT__ be the same as my evaluation results.\n",
    "\n",
    "Let's start with loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import required package for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import required packages for splitting data\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import required packages for evaluating models\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# import `logistic regression` model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you should load __your__ data. In this case, I am using a sample dataset (`GroupX.csv`) which contains 6 predictors (`X1 - X6`) and two target variables (`Y1, Y2`).\n",
    "\n",
    "Please make sure you change the data to your __OWN__ dataset when using this code.\n",
    "\n",
    "__NOTE__:\n",
    "1. Your dataset maybe very different from the sample dataset.\n",
    "2. Please follow this structure when submitting your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>P(mid)</th>\n",
       "      <th>Long_to_Total_Sentences</th>\n",
       "      <th>Pos_to_Total_Words</th>\n",
       "      <th>Neg_to_Total_Words</th>\n",
       "      <th>Pos_Neg_Words</th>\n",
       "      <th>Long_to_Total_Words</th>\n",
       "      <th>Real_to_Total_Words</th>\n",
       "      <th>C3P</th>\n",
       "      <th>C5P</th>\n",
       "      <th>C6P</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.029074</td>\n",
       "      <td>40962052.0</td>\n",
       "      <td>10600000.0</td>\n",
       "      <td>51.345</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.640426</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>1</td>\n",
       "      <td>3.864345</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259.0</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>-0.013352</td>\n",
       "      <td>28869196.0</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>25.936</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.644753</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.898724</td>\n",
       "      <td>0</td>\n",
       "      <td>12.028832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>16845668.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>7.378</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>1.848485</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>0.909350</td>\n",
       "      <td>0</td>\n",
       "      <td>3.369134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209.0</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.020023</td>\n",
       "      <td>14848637.0</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>8.526</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.917060</td>\n",
       "      <td>0</td>\n",
       "      <td>3.299697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.034895</td>\n",
       "      <td>30741716.0</td>\n",
       "      <td>8250000.0</td>\n",
       "      <td>632.298</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.048550</td>\n",
       "      <td>0.888469</td>\n",
       "      <td>1</td>\n",
       "      <td>3.726269</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C1    C3        C4          C5          C6       C7  P(mid)  \\\n",
       "0  122.0  3.43  0.029074  40962052.0  10600000.0   51.345     9.0   \n",
       "1  259.0 -1.62 -0.013352  28869196.0   2400000.0   25.936     9.0   \n",
       "2   90.0 -1.24  0.020715  16845668.0   5000000.0    7.378    13.0   \n",
       "3  209.0 -0.91  0.020023  14848637.0   4500000.0    8.526    15.0   \n",
       "4   80.0  0.07 -0.034895  30741716.0   8250000.0  632.298    20.0   \n",
       "\n",
       "   Long_to_Total_Sentences  Pos_to_Total_Words  Neg_to_Total_Words  \\\n",
       "0                 0.640426            0.004875            0.009199   \n",
       "1                 0.644753            0.003258            0.011105   \n",
       "2                 0.636816            0.011593            0.006271   \n",
       "3                 0.539634            0.009686            0.007144   \n",
       "4                 0.587413            0.004518            0.010047   \n",
       "\n",
       "   Pos_Neg_Words  Long_to_Total_Words  Real_to_Total_Words  C3P        C5P  \\\n",
       "0       0.529915             0.054250             0.908876    1   3.864345   \n",
       "1       0.293388             0.051395             0.898724    0  12.028832   \n",
       "2       1.848485             0.061764             0.909350    0   3.369134   \n",
       "3       1.355932             0.061630             0.917060    0   3.299697   \n",
       "4       0.449664             0.048550             0.888469    1   3.726269   \n",
       "\n",
       "         C6P  Y1  Y2  \n",
       "0  11.111111   0   1  \n",
       "1   0.000000   1   0  \n",
       "2   0.000000   1   0  \n",
       "3   0.000000   1   1  \n",
       "4   5.000000   0   1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('evalbase.csv', header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking your data types and make sure it follows the data dictionary would be an important step, you can do that using the `.dtypes` attribute.\n",
    "\n",
    "__NOTE__: all __continuous__ faetures will be in `float64` data type, and all __categorical__ features will be in `int64` data type (given you already coded (per __suggest task \\#6__ in the competition document) them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1                         float64\n",
       "C3                         float64\n",
       "C4                         float64\n",
       "C5                         float64\n",
       "C6                         float64\n",
       "C7                         float64\n",
       "P(mid)                     float64\n",
       "Long_to_Total_Sentences    float64\n",
       "Pos_to_Total_Words         float64\n",
       "Neg_to_Total_Words         float64\n",
       "Pos_Neg_Words              float64\n",
       "Long_to_Total_Words        float64\n",
       "Real_to_Total_Words        float64\n",
       "C3P                          int64\n",
       "C5P                        float64\n",
       "C6P                        float64\n",
       "Y1                           int64\n",
       "Y2                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to specify your targets and predictors. __NOTE__ we have two targets here (`Y1, Y2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = data.Y1\n",
    "y2 = data.Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 18)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very possible that you will use different sets of the predictors for `Y1` and `Y2`. Now let's define them.\n",
    "\n",
    "First, let's define predictors for `Y1` - which will be the first 5 features in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C1',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C7',\n",
       " 'P(mid)',\n",
       " 'Long_to_Total_Sentences',\n",
       " 'Pos_to_Total_Words',\n",
       " 'Neg_to_Total_Words',\n",
       " 'Pos_Neg_Words',\n",
       " 'Long_to_Total_Words',\n",
       " 'Real_to_Total_Words',\n",
       " 'C3P',\n",
       " 'C5P',\n",
       " 'C6P']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(data.columns)\n",
    "# first 5 features \n",
    "cols[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code to select the first 5 features as predictors for `Y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>P(mid)</th>\n",
       "      <th>Long_to_Total_Sentences</th>\n",
       "      <th>Pos_to_Total_Words</th>\n",
       "      <th>Neg_to_Total_Words</th>\n",
       "      <th>Pos_Neg_Words</th>\n",
       "      <th>Long_to_Total_Words</th>\n",
       "      <th>Real_to_Total_Words</th>\n",
       "      <th>C3P</th>\n",
       "      <th>C5P</th>\n",
       "      <th>C6P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.029074</td>\n",
       "      <td>40962052.0</td>\n",
       "      <td>10600000.0</td>\n",
       "      <td>51.345</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.640426</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>1</td>\n",
       "      <td>3.864345</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259.0</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>-0.013352</td>\n",
       "      <td>28869196.0</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>25.936</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.644753</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.898724</td>\n",
       "      <td>0</td>\n",
       "      <td>12.028832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>16845668.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>7.378</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>1.848485</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>0.909350</td>\n",
       "      <td>0</td>\n",
       "      <td>3.369134</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209.0</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.020023</td>\n",
       "      <td>14848637.0</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>8.526</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.917060</td>\n",
       "      <td>0</td>\n",
       "      <td>3.299697</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.034895</td>\n",
       "      <td>30741716.0</td>\n",
       "      <td>8250000.0</td>\n",
       "      <td>632.298</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.048550</td>\n",
       "      <td>0.888469</td>\n",
       "      <td>1</td>\n",
       "      <td>3.726269</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C1    C3        C4          C5          C6       C7  P(mid)  \\\n",
       "0  122.0  3.43  0.029074  40962052.0  10600000.0   51.345     9.0   \n",
       "1  259.0 -1.62 -0.013352  28869196.0   2400000.0   25.936     9.0   \n",
       "2   90.0 -1.24  0.020715  16845668.0   5000000.0    7.378    13.0   \n",
       "3  209.0 -0.91  0.020023  14848637.0   4500000.0    8.526    15.0   \n",
       "4   80.0  0.07 -0.034895  30741716.0   8250000.0  632.298    20.0   \n",
       "\n",
       "   Long_to_Total_Sentences  Pos_to_Total_Words  Neg_to_Total_Words  \\\n",
       "0                 0.640426            0.004875            0.009199   \n",
       "1                 0.644753            0.003258            0.011105   \n",
       "2                 0.636816            0.011593            0.006271   \n",
       "3                 0.539634            0.009686            0.007144   \n",
       "4                 0.587413            0.004518            0.010047   \n",
       "\n",
       "   Pos_Neg_Words  Long_to_Total_Words  Real_to_Total_Words  C3P        C5P  \\\n",
       "0       0.529915             0.054250             0.908876    1   3.864345   \n",
       "1       0.293388             0.051395             0.898724    0  12.028832   \n",
       "2       1.848485             0.061764             0.909350    0   3.369134   \n",
       "3       1.355932             0.061630             0.917060    0   3.299697   \n",
       "4       0.449664             0.048550             0.888469    1   3.726269   \n",
       "\n",
       "         C6P  \n",
       "0  11.111111  \n",
       "1   0.000000  \n",
       "2   0.000000  \n",
       "3   0.000000  \n",
       "4   5.000000  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_y1 = data[cols[:-2]]\n",
    "predictors_y1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon investigation of the data, we know we have __six__ features (`X1 - X6`) predicting `Y2`. Use similar code (as below) to select them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>C1</th>\n",
       "      <th>C3</th>\n",
       "      <th>C4</th>\n",
       "      <th>C5</th>\n",
       "      <th>C6</th>\n",
       "      <th>C7</th>\n",
       "      <th>P(mid)</th>\n",
       "      <th>Long_to_Total_Sentences</th>\n",
       "      <th>Pos_to_Total_Words</th>\n",
       "      <th>Neg_to_Total_Words</th>\n",
       "      <th>Pos_Neg_Words</th>\n",
       "      <th>Long_to_Total_Words</th>\n",
       "      <th>Real_to_Total_Words</th>\n",
       "      <th>C3P</th>\n",
       "      <th>C5P</th>\n",
       "      <th>C6P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>122.0</td>\n",
       "      <td>3.43</td>\n",
       "      <td>0.029074</td>\n",
       "      <td>40962052.0</td>\n",
       "      <td>10600000.0</td>\n",
       "      <td>51.345</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.640426</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>1</td>\n",
       "      <td>3.864345</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>259.0</td>\n",
       "      <td>-1.62</td>\n",
       "      <td>-0.013352</td>\n",
       "      <td>28869196.0</td>\n",
       "      <td>2400000.0</td>\n",
       "      <td>25.936</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.644753</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.898724</td>\n",
       "      <td>0</td>\n",
       "      <td>12.028832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90.0</td>\n",
       "      <td>-1.24</td>\n",
       "      <td>0.020715</td>\n",
       "      <td>16845668.0</td>\n",
       "      <td>5000000.0</td>\n",
       "      <td>7.378</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>1.848485</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>0.909350</td>\n",
       "      <td>0</td>\n",
       "      <td>3.369134</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209.0</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.020023</td>\n",
       "      <td>14848637.0</td>\n",
       "      <td>4500000.0</td>\n",
       "      <td>8.526</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.917060</td>\n",
       "      <td>0</td>\n",
       "      <td>3.299697</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.034895</td>\n",
       "      <td>30741716.0</td>\n",
       "      <td>8250000.0</td>\n",
       "      <td>632.298</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.048550</td>\n",
       "      <td>0.888469</td>\n",
       "      <td>1</td>\n",
       "      <td>3.726269</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      C1    C3        C4          C5          C6       C7  P(mid)  \\\n",
       "0  122.0  3.43  0.029074  40962052.0  10600000.0   51.345     9.0   \n",
       "1  259.0 -1.62 -0.013352  28869196.0   2400000.0   25.936     9.0   \n",
       "2   90.0 -1.24  0.020715  16845668.0   5000000.0    7.378    13.0   \n",
       "3  209.0 -0.91  0.020023  14848637.0   4500000.0    8.526    15.0   \n",
       "4   80.0  0.07 -0.034895  30741716.0   8250000.0  632.298    20.0   \n",
       "\n",
       "   Long_to_Total_Sentences  Pos_to_Total_Words  Neg_to_Total_Words  \\\n",
       "0                 0.640426            0.004875            0.009199   \n",
       "1                 0.644753            0.003258            0.011105   \n",
       "2                 0.636816            0.011593            0.006271   \n",
       "3                 0.539634            0.009686            0.007144   \n",
       "4                 0.587413            0.004518            0.010047   \n",
       "\n",
       "   Pos_Neg_Words  Long_to_Total_Words  Real_to_Total_Words  C3P        C5P  \\\n",
       "0       0.529915             0.054250             0.908876    1   3.864345   \n",
       "1       0.293388             0.051395             0.898724    0  12.028832   \n",
       "2       1.848485             0.061764             0.909350    0   3.369134   \n",
       "3       1.355932             0.061630             0.917060    0   3.299697   \n",
       "4       0.449664             0.048550             0.888469    1   3.726269   \n",
       "\n",
       "         C6P  \n",
       "0  11.111111  \n",
       "1   0.000000  \n",
       "2   0.000000  \n",
       "3   0.000000  \n",
       "4   5.000000  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_y2 = data[cols[:-2]]\n",
    "predictors_y2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the key part of this notebook - which generates a `logistic regression` model to predict `Y1`/`Y2`.\n",
    "\n",
    "The code works this way:\n",
    "\n",
    "1. We generate two lists `f1_score_lst` and `auc_lst` to store f1_score and AUC from each of the `10` runs of the model;\n",
    "2. Define model:\n",
    "    1. We define a `LogisticRegression()` model;\n",
    "    \n",
    "    2. We split predictors (`predictors_y1`) and target `y1` to training (80%) and testing (20%);\n",
    "    \n",
    "    3. We fit the model `clf` to the training data, then use it to predict on the testing data;\n",
    "    \n",
    "    4. We also defined a `10-fold cross validation` to make sure our model do not overfit - see [here](https://scikit-learn.org/stable/modules/cross_validation.html) for more info;\n",
    "    \n",
    "    5. We append the f1_score and AUC of current model to the lists (`f1_score_lst` and `auc_lst`) we defined earlier.\n",
    "  \n",
    "3. Print out average f1_score and AUC for all 10 runs;\n",
    "4. Print out average average accuracy from cross validation\n",
    "5. Print out confusion matrix and classification report for the __last__ model.\n",
    "\n",
    "__NOTE__: Step 3 provides the evaluation results we need; step 4 - 5 can be used to verify the results from step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.3589; AUC 0.5124 \n",
      "Accuracy of classifier on test set: 0.49\n",
      "10-fold cross validation average accuracy of classifier: 0.488\n",
      "Confusion Matrix for Logistic Regression Classfier:\n",
      "[[63  2]\n",
      " [68  4]]\n",
      "Classification Report for Logistic Regression Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.97      0.64        65\n",
      "           1       0.67      0.06      0.10        72\n",
      "\n",
      "    accuracy                           0.49       137\n",
      "   macro avg       0.57      0.51      0.37       137\n",
      "weighted avg       0.58      0.49      0.36       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    #Model building\n",
    "    clf = LogisticRegression()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(predictors_y1, y1, test_size=0.2, random_state=123)\n",
    "    clf.fit(X1_train, y1_train)\n",
    "\n",
    "    y1_pred = clf.predict(X1_test)\n",
    "\n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf, X1_train, y1_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf_roc_auc = roc_auc_score(y1_test, y1_pred)\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y1_test, y1_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf_roc_auc)\n",
    "\n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "#result=logit_model.fit()\n",
    "confusion_matrix_y1 = confusion_matrix(y1_test, y1_pred)\n",
    "\n",
    "\n",
    "#print(result.summary())\n",
    "print('Accuracy of classifier on test set: {:.2f}'.format(clf.score(X1_test, y1_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of classifier: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Logistic Regression Classfier:')\n",
    "print(confusion_matrix_y1)\n",
    "\n",
    "print('Classification Report for Logistic Regression Classfier:')\n",
    "print(classification_report(y1_test, y1_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code are used to evaluate model toward `Y2`. It is very similar to the code above - key difference is that `Y2` is imbalanced - so I wrote some code (under `# Begin oversampling`) to deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 0.5509; AUC 0.5477 \n",
      "Accuracy of classifier on test set: 0.533\n",
      "10-fold cross validation average accuracy of clf1: 0.368\n",
      "Confusion Matrix for Classfier:\n",
      "[[26 18]\n",
      " [46 47]]\n",
      "Classification Report for Classfier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.59      0.45        44\n",
      "           1       0.72      0.51      0.59        93\n",
      "\n",
      "    accuracy                           0.53       137\n",
      "   macro avg       0.54      0.55      0.52       137\n",
      "weighted avg       0.61      0.53      0.55       137\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/sklearn/model_selection/_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    #Model building\n",
    "    clf1 = LogisticRegression()\n",
    "\n",
    "    \n",
    "    # Splitting data into testing and training\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(predictors_y2, y2, test_size=0.2, random_state=123)\n",
    "    \n",
    "    # Begin oversampling\n",
    "    oversample = pd.concat([X2_train,y2_train],axis=1)\n",
    "    max_size = oversample['Y2'].value_counts().max()\n",
    "    lst = [oversample]\n",
    "    for class_index, group in oversample.groupby('Y2'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    X2_train = pd.concat(lst)\n",
    "    y2_train=pd.DataFrame.copy(X2_train['Y2'])\n",
    "    del X2_train['Y2']\n",
    "    \n",
    "    # fitting model on oversampled data\n",
    "    clf1.fit(X2_train, y2_train)\n",
    "    \n",
    "    y2_pred = clf1.predict(X2_test)\n",
    "    \n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf1, X2_train, y2_train, cv=kfold, scoring=scoring)\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf1_roc_auc = roc_auc_score(y2_test, y2_pred)\n",
    "    \n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y2_test, y2_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf1_roc_auc)\n",
    "    \n",
    "    \n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "confusion_matrix_y2 = confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf1.score(X2_test, y2_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf1: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y2)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y2_test, y2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
