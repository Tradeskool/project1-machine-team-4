{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example Evaluation Code\n",
    "\n",
    "This notebook will be very __similar__ to the code I use to evaluate your results - it is provided for __your convenience__ so that you can use it to evaluate your preprocessing results at any time before your __final submission__.\n",
    "\n",
    "Please note that the results here will __NOT__ be the same as my evaluation results.\n",
    "\n",
    "Let's start with loading the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import required package for data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import required packages for splitting data\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import required packages for evaluating models\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# import `logistic regression` model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you should load __your__ data. In this case, I am using a sample dataset (`GroupX.csv`) which contains 6 predictors (`X1 - X6`) and two target variables (`Y1, Y2`).\n",
    "\n",
    "Please make sure you change the data to your __OWN__ dataset when using this code.\n",
    "\n",
    "__NOTE__:\n",
    "1. Your dataset maybe very different from the sample dataset.\n",
    "2. Please follow this structure when submitting your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>P(IPO)</th>\n",
       "      <th>P(H)</th>\n",
       "      <th>P(L)</th>\n",
       "      <th>P(1Day)</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>...</th>\n",
       "      <th>Pos_to_Total_Words</th>\n",
       "      <th>Neg_to_Total_Words</th>\n",
       "      <th>Pos_Neg_Words</th>\n",
       "      <th>Long_to_Total_Words</th>\n",
       "      <th>Real_to_Total_Words</th>\n",
       "      <th>C3P</th>\n",
       "      <th>C5P</th>\n",
       "      <th>C6P</th>\n",
       "      <th>Y1</th>\n",
       "      <th>Y2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AATI</td>\n",
       "      <td>ADVANCED ANALOGIC TECHNOLOGIES INC</td>\n",
       "      <td>3674</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.870000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>1</td>\n",
       "      <td>3.864345</td>\n",
       "      <td>11.111111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ABPI</td>\n",
       "      <td>ACCENTIA BIOPHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.898724</td>\n",
       "      <td>0</td>\n",
       "      <td>12.028832</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>ACADIA PHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>1.848485</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>0.909350</td>\n",
       "      <td>0</td>\n",
       "      <td>3.369134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ACHN</td>\n",
       "      <td>ACHILLION PHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>11.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.390000</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.917060</td>\n",
       "      <td>0</td>\n",
       "      <td>3.299697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACLI</td>\n",
       "      <td>AMERICAN COMMERCIAL LINES INC.</td>\n",
       "      <td>4492</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.048550</td>\n",
       "      <td>0.888469</td>\n",
       "      <td>1</td>\n",
       "      <td>3.726269</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    I1                                  I2    I3  P(IPO)  P(H)  \\\n",
       "0           0  AATI  ADVANCED ANALOGIC TECHNOLOGIES INC  3674    10.0   9.5   \n",
       "1           1  ABPI     ACCENTIA BIOPHARMACEUTICALS INC  2834     8.0  10.0   \n",
       "2           2  ACAD          ACADIA PHARMACEUTICALS INC  2834     7.0  14.0   \n",
       "3           3  ACHN       ACHILLION PHARMACEUTICALS INC  2834    11.5  16.0   \n",
       "4           4  ACLI     AMERICAN COMMERCIAL LINES INC.   4492    21.0  21.0   \n",
       "\n",
       "   P(L)    P(1Day)     C1   C2  ...  Pos_to_Total_Words  Neg_to_Total_Words  \\\n",
       "0   8.5  11.870000  122.0  1.0  ...            0.004875            0.009199   \n",
       "1   8.0   7.250000  259.0  0.0  ...            0.003258            0.011105   \n",
       "2  12.0   6.700000   90.0  1.0  ...            0.011593            0.006271   \n",
       "3  14.0  12.390000  209.0  1.0  ...            0.009686            0.007144   \n",
       "4  19.0  56.599998   80.0  1.0  ...            0.004518            0.010047   \n",
       "\n",
       "   Pos_Neg_Words  Long_to_Total_Words  Real_to_Total_Words  C3P        C5P  \\\n",
       "0       0.529915             0.054250             0.908876    1   3.864345   \n",
       "1       0.293388             0.051395             0.898724    0  12.028832   \n",
       "2       1.848485             0.061764             0.909350    0   3.369134   \n",
       "3       1.355932             0.061630             0.917060    0   3.299697   \n",
       "4       0.449664             0.048550             0.888469    1   3.726269   \n",
       "\n",
       "         C6P  Y1  Y2  \n",
       "0  11.111111   0   1  \n",
       "1   0.000000   1   0  \n",
       "2   0.000000   1   0  \n",
       "3   0.000000   1   1  \n",
       "4   5.000000   0   1  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('evaltest.csv', header=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking your data types and make sure it follows the data dictionary would be an important step, you can do that using the `.dtypes` attribute.\n",
    "\n",
    "__NOTE__: all __continuous__ faetures will be in `float64` data type, and all __categorical__ features will be in `int64` data type (given you already coded (per __suggest task \\#6__ in the competition document) them)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                   int64\n",
       "I1                          object\n",
       "I2                          object\n",
       "I3                           int64\n",
       "P(IPO)                     float64\n",
       "P(H)                       float64\n",
       "P(L)                       float64\n",
       "P(1Day)                    float64\n",
       "C1                         float64\n",
       "C2                         float64\n",
       "C3                         float64\n",
       "C4                         float64\n",
       "C5                         float64\n",
       "C6                         float64\n",
       "C7                         float64\n",
       "T1                         float64\n",
       "T2                         float64\n",
       "T3                         float64\n",
       "T4                         float64\n",
       "T5                         float64\n",
       "S1                         float64\n",
       "S2                         float64\n",
       "S3                         float64\n",
       "P(mid)                     float64\n",
       "Long_to_Total_Sentences    float64\n",
       "Pos_to_Total_Words         float64\n",
       "Neg_to_Total_Words         float64\n",
       "Pos_Neg_Words              float64\n",
       "Long_to_Total_Words        float64\n",
       "Real_to_Total_Words        float64\n",
       "C3P                          int64\n",
       "C5P                        float64\n",
       "C6P                        float64\n",
       "Y1                           int64\n",
       "Y2                           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you need to specify your targets and predictors. __NOTE__ we have two targets here (`Y1, Y2`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y1 = data.Y1\n",
    "y2 = data.Y2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 35)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is very possible that you will use different sets of the predictors for `Y1` and `Y2`. Now let's define them.\n",
    "\n",
    "First, let's define predictors for `Y1` - which will be the first 5 features in `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'I1',\n",
       " 'I2',\n",
       " 'I3',\n",
       " 'P(IPO)',\n",
       " 'P(H)',\n",
       " 'P(L)',\n",
       " 'P(1Day)',\n",
       " 'C1',\n",
       " 'C2',\n",
       " 'C3',\n",
       " 'C4',\n",
       " 'C5',\n",
       " 'C6',\n",
       " 'C7',\n",
       " 'T1',\n",
       " 'T2',\n",
       " 'T3',\n",
       " 'T4',\n",
       " 'T5',\n",
       " 'S1',\n",
       " 'S2',\n",
       " 'S3',\n",
       " 'P(mid)',\n",
       " 'Long_to_Total_Sentences',\n",
       " 'Pos_to_Total_Words',\n",
       " 'Neg_to_Total_Words',\n",
       " 'Pos_Neg_Words',\n",
       " 'Long_to_Total_Words',\n",
       " 'Real_to_Total_Words',\n",
       " 'C3P',\n",
       " 'C5P']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = list(data.columns)\n",
    "# first 5 features \n",
    "cols[:-3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use below code to select the first 5 features as predictors for `Y1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>P(IPO)</th>\n",
       "      <th>P(H)</th>\n",
       "      <th>P(L)</th>\n",
       "      <th>P(1Day)</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>...</th>\n",
       "      <th>S3</th>\n",
       "      <th>P(mid)</th>\n",
       "      <th>Long_to_Total_Sentences</th>\n",
       "      <th>Pos_to_Total_Words</th>\n",
       "      <th>Neg_to_Total_Words</th>\n",
       "      <th>Pos_Neg_Words</th>\n",
       "      <th>Long_to_Total_Words</th>\n",
       "      <th>Real_to_Total_Words</th>\n",
       "      <th>C3P</th>\n",
       "      <th>C5P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AATI</td>\n",
       "      <td>ADVANCED ANALOGIC TECHNOLOGIES INC</td>\n",
       "      <td>3674</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.870000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.640426</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>1</td>\n",
       "      <td>3.864345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ABPI</td>\n",
       "      <td>ACCENTIA BIOPHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>237.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.644753</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.898724</td>\n",
       "      <td>0</td>\n",
       "      <td>12.028832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>ACADIA PHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>60.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>1.848485</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>0.909350</td>\n",
       "      <td>0</td>\n",
       "      <td>3.369134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ACHN</td>\n",
       "      <td>ACHILLION PHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>11.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.390000</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>110.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.917060</td>\n",
       "      <td>0</td>\n",
       "      <td>3.299697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACLI</td>\n",
       "      <td>AMERICAN COMMERCIAL LINES INC.</td>\n",
       "      <td>4492</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>167.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.048550</td>\n",
       "      <td>0.888469</td>\n",
       "      <td>1</td>\n",
       "      <td>3.726269</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    I1                                  I2    I3  P(IPO)  P(H)  \\\n",
       "0           0  AATI  ADVANCED ANALOGIC TECHNOLOGIES INC  3674    10.0   9.5   \n",
       "1           1  ABPI     ACCENTIA BIOPHARMACEUTICALS INC  2834     8.0  10.0   \n",
       "2           2  ACAD          ACADIA PHARMACEUTICALS INC  2834     7.0  14.0   \n",
       "3           3  ACHN       ACHILLION PHARMACEUTICALS INC  2834    11.5  16.0   \n",
       "4           4  ACLI     AMERICAN COMMERCIAL LINES INC.   4492    21.0  21.0   \n",
       "\n",
       "   P(L)    P(1Day)     C1   C2  ...     S3  P(mid)  Long_to_Total_Sentences  \\\n",
       "0   8.5  11.870000  122.0  1.0  ...  139.0     9.0                 0.640426   \n",
       "1   8.0   7.250000  259.0  0.0  ...  237.0     9.0                 0.644753   \n",
       "2  12.0   6.700000   90.0  1.0  ...   60.0    13.0                 0.636816   \n",
       "3  14.0  12.390000  209.0  1.0  ...  110.0    15.0                 0.539634   \n",
       "4  19.0  56.599998   80.0  1.0  ...  167.0    20.0                 0.587413   \n",
       "\n",
       "   Pos_to_Total_Words  Neg_to_Total_Words  Pos_Neg_Words  Long_to_Total_Words  \\\n",
       "0            0.004875            0.009199       0.529915             0.054250   \n",
       "1            0.003258            0.011105       0.293388             0.051395   \n",
       "2            0.011593            0.006271       1.848485             0.061764   \n",
       "3            0.009686            0.007144       1.355932             0.061630   \n",
       "4            0.004518            0.010047       0.449664             0.048550   \n",
       "\n",
       "   Real_to_Total_Words  C3P        C5P  \n",
       "0             0.908876    1   3.864345  \n",
       "1             0.898724    0  12.028832  \n",
       "2             0.909350    0   3.369134  \n",
       "3             0.917060    0   3.299697  \n",
       "4             0.888469    1   3.726269  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_y1 = data[cols[:-3]]\n",
    "predictors_y1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upon investigation of the data, we know we have __six__ features (`X1 - X6`) predicting `Y2`. Use similar code (as below) to select them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>I1</th>\n",
       "      <th>I2</th>\n",
       "      <th>I3</th>\n",
       "      <th>P(IPO)</th>\n",
       "      <th>P(H)</th>\n",
       "      <th>P(L)</th>\n",
       "      <th>P(1Day)</th>\n",
       "      <th>C1</th>\n",
       "      <th>C2</th>\n",
       "      <th>...</th>\n",
       "      <th>P(mid)</th>\n",
       "      <th>Long_to_Total_Sentences</th>\n",
       "      <th>Pos_to_Total_Words</th>\n",
       "      <th>Neg_to_Total_Words</th>\n",
       "      <th>Pos_Neg_Words</th>\n",
       "      <th>Long_to_Total_Words</th>\n",
       "      <th>Real_to_Total_Words</th>\n",
       "      <th>C3P</th>\n",
       "      <th>C5P</th>\n",
       "      <th>C6P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AATI</td>\n",
       "      <td>ADVANCED ANALOGIC TECHNOLOGIES INC</td>\n",
       "      <td>3674</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.5</td>\n",
       "      <td>8.5</td>\n",
       "      <td>11.870000</td>\n",
       "      <td>122.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.640426</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.009199</td>\n",
       "      <td>0.529915</td>\n",
       "      <td>0.054250</td>\n",
       "      <td>0.908876</td>\n",
       "      <td>1</td>\n",
       "      <td>3.864345</td>\n",
       "      <td>11.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ABPI</td>\n",
       "      <td>ACCENTIA BIOPHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.250000</td>\n",
       "      <td>259.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.644753</td>\n",
       "      <td>0.003258</td>\n",
       "      <td>0.011105</td>\n",
       "      <td>0.293388</td>\n",
       "      <td>0.051395</td>\n",
       "      <td>0.898724</td>\n",
       "      <td>0</td>\n",
       "      <td>12.028832</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>ACAD</td>\n",
       "      <td>ACADIA PHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>7.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.700000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.636816</td>\n",
       "      <td>0.011593</td>\n",
       "      <td>0.006271</td>\n",
       "      <td>1.848485</td>\n",
       "      <td>0.061764</td>\n",
       "      <td>0.909350</td>\n",
       "      <td>0</td>\n",
       "      <td>3.369134</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ACHN</td>\n",
       "      <td>ACHILLION PHARMACEUTICALS INC</td>\n",
       "      <td>2834</td>\n",
       "      <td>11.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.390000</td>\n",
       "      <td>209.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.539634</td>\n",
       "      <td>0.009686</td>\n",
       "      <td>0.007144</td>\n",
       "      <td>1.355932</td>\n",
       "      <td>0.061630</td>\n",
       "      <td>0.917060</td>\n",
       "      <td>0</td>\n",
       "      <td>3.299697</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACLI</td>\n",
       "      <td>AMERICAN COMMERCIAL LINES INC.</td>\n",
       "      <td>4492</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>56.599998</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.004518</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>0.449664</td>\n",
       "      <td>0.048550</td>\n",
       "      <td>0.888469</td>\n",
       "      <td>1</td>\n",
       "      <td>3.726269</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    I1                                  I2    I3  P(IPO)  P(H)  \\\n",
       "0           0  AATI  ADVANCED ANALOGIC TECHNOLOGIES INC  3674    10.0   9.5   \n",
       "1           1  ABPI     ACCENTIA BIOPHARMACEUTICALS INC  2834     8.0  10.0   \n",
       "2           2  ACAD          ACADIA PHARMACEUTICALS INC  2834     7.0  14.0   \n",
       "3           3  ACHN       ACHILLION PHARMACEUTICALS INC  2834    11.5  16.0   \n",
       "4           4  ACLI     AMERICAN COMMERCIAL LINES INC.   4492    21.0  21.0   \n",
       "\n",
       "   P(L)    P(1Day)     C1   C2  ...  P(mid)  Long_to_Total_Sentences  \\\n",
       "0   8.5  11.870000  122.0  1.0  ...     9.0                 0.640426   \n",
       "1   8.0   7.250000  259.0  0.0  ...     9.0                 0.644753   \n",
       "2  12.0   6.700000   90.0  1.0  ...    13.0                 0.636816   \n",
       "3  14.0  12.390000  209.0  1.0  ...    15.0                 0.539634   \n",
       "4  19.0  56.599998   80.0  1.0  ...    20.0                 0.587413   \n",
       "\n",
       "   Pos_to_Total_Words  Neg_to_Total_Words  Pos_Neg_Words  Long_to_Total_Words  \\\n",
       "0            0.004875            0.009199       0.529915             0.054250   \n",
       "1            0.003258            0.011105       0.293388             0.051395   \n",
       "2            0.011593            0.006271       1.848485             0.061764   \n",
       "3            0.009686            0.007144       1.355932             0.061630   \n",
       "4            0.004518            0.010047       0.449664             0.048550   \n",
       "\n",
       "   Real_to_Total_Words  C3P        C5P        C6P  \n",
       "0             0.908876    1   3.864345  11.111111  \n",
       "1             0.898724    0  12.028832   0.000000  \n",
       "2             0.909350    0   3.369134   0.000000  \n",
       "3             0.917060    0   3.299697   0.000000  \n",
       "4             0.888469    1   3.726269   5.000000  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors_y2 = data[cols[:-2]]\n",
    "predictors_y2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the key part of this notebook - which generates a `logistic regression` model to predict `Y1`/`Y2`.\n",
    "\n",
    "The code works this way:\n",
    "\n",
    "1. We generate two lists `f1_score_lst` and `auc_lst` to store f1_score and AUC from each of the `10` runs of the model;\n",
    "2. Define model:\n",
    "    1. We define a `LogisticRegression()` model;\n",
    "    \n",
    "    2. We split predictors (`predictors_y1`) and target `y1` to training (80%) and testing (20%);\n",
    "    \n",
    "    3. We fit the model `clf` to the training data, then use it to predict on the testing data;\n",
    "    \n",
    "    4. We also defined a `10-fold cross validation` to make sure our model do not overfit - see [here](https://scikit-learn.org/stable/modules/cross_validation.html) for more info;\n",
    "    \n",
    "    5. We append the f1_score and AUC of current model to the lists (`f1_score_lst` and `auc_lst`) we defined earlier.\n",
    "  \n",
    "3. Print out average f1_score and AUC for all 10 runs;\n",
    "4. Print out average average accuracy from cross validation\n",
    "5. Print out confusion matrix and classification report for the __last__ model.\n",
    "\n",
    "__NOTE__: Step 3 provides the evaluation results we need; step 4 - 5 can be used to verify the results from step 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'RSC Holdings Inc.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-a69d12629b18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mX1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX1_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictors_y1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m123\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0my1_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'RSC Holdings Inc.'"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    #Model building\n",
    "    clf = LogisticRegression()\n",
    "    X1_train, X1_test, y1_train, y1_test = train_test_split(predictors_y1, y1, test_size=0.2, random_state=123)\n",
    "    clf.fit(X1_train, y1_train)\n",
    "\n",
    "    y1_pred = clf.predict(X1_test)\n",
    "\n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=7)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf, X1_train, y1_train, cv=kfold, scoring=scoring)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf_roc_auc = roc_auc_score(y1_test, y1_pred)\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y1_test, y1_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf_roc_auc)\n",
    "\n",
    "\n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "#result=logit_model.fit()\n",
    "confusion_matrix_y1 = confusion_matrix(y1_test, y1_pred)\n",
    "\n",
    "\n",
    "#print(result.summary())\n",
    "print('Accuracy of classifier on test set: {:.2f}'.format(clf.score(X1_test, y1_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of classifier: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Logistic Regression Classfier:')\n",
    "print(confusion_matrix_y1)\n",
    "\n",
    "print('Classification Report for Logistic Regression Classfier:')\n",
    "print(classification_report(y1_test, y1_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code are used to evaluate model toward `Y2`. It is very similar to the code above - key difference is that `Y2` is imbalanced - so I wrote some code (under `# Begin oversampling`) to deal with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'FriendFinder Networks Inc.\\xa0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bbe93a553303>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# fitting model on oversampled data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my2_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0my2_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX2_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m         X, y = check_X_y(X, y, accept_sparse='csr', dtype=_dtype, order=\"C\",\n\u001b[0;32m-> 1527\u001b[0;31m                          accept_large_sparse=solver != 'liblinear')\n\u001b[0m\u001b[1;32m   1528\u001b[0m         \u001b[0mcheck_classification_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m                     estimator=estimator)\n\u001b[0m\u001b[1;32m    756\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[0;32m/opt/tljh/user/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'FriendFinder Networks Inc.\\xa0'"
     ]
    }
   ],
   "source": [
    "# lists for f1-score and AUC\n",
    "f1_score_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "\n",
    "#loop to calculate f1 and auc scores and present averages after 10 runs\n",
    "for count in range (1,10):\n",
    "    #Model building\n",
    "    clf1 = LogisticRegression()\n",
    "\n",
    "    \n",
    "    # Splitting data into testing and training\n",
    "    X2_train, X2_test, y2_train, y2_test = train_test_split(predictors_y2, y2, test_size=0.2, random_state=123)\n",
    "    \n",
    "    # Begin oversampling\n",
    "    oversample = pd.concat([X2_train,y2_train],axis=1)\n",
    "    max_size = oversample['Y2'].value_counts().max()\n",
    "    lst = [oversample]\n",
    "    for class_index, group in oversample.groupby('Y2'):\n",
    "        lst.append(group.sample(max_size-len(group), replace=True))\n",
    "    X2_train = pd.concat(lst)\n",
    "    y2_train=pd.DataFrame.copy(X2_train['Y2'])\n",
    "    del X2_train['Y2']\n",
    "    \n",
    "    # fitting model on oversampled data\n",
    "    clf1.fit(X2_train, y2_train)\n",
    "    \n",
    "    y2_pred = clf1.predict(X2_test)\n",
    "    \n",
    "    \n",
    "    #10-fold cross validation\n",
    "    kfold = model_selection.KFold(n_splits=10, random_state=123)\n",
    "    scoring = 'accuracy'\n",
    "    results = model_selection.cross_val_score(clf1, X2_train, y2_train, cv=kfold, scoring=scoring)\n",
    "    \n",
    "    #calculate f1-score and AUC\n",
    "    \n",
    "    clf1_roc_auc = roc_auc_score(y2_test, y2_pred)\n",
    "    \n",
    "    \n",
    "    #calculate average f1-score and AUC\n",
    "    f1_score_lst.append(precision_recall_fscore_support(y2_test, y2_pred, average='weighted')[2])\n",
    "    auc_lst.append(clf1_roc_auc)\n",
    "    \n",
    "    \n",
    "print('F1 {:.4f}; AUC {:.4f} '.format(np.mean(f1_score_lst),np.mean(auc_lst)))\n",
    "\n",
    "confusion_matrix_y2 = confusion_matrix(y2_test, y2_pred)\n",
    "\n",
    "\n",
    "print('Accuracy of classifier on test set: {:.3f}'.format(clf1.score(X2_test, y2_test)))\n",
    "\n",
    "print(\"10-fold cross validation average accuracy of clf1: %.3f\" % (results.mean()))\n",
    "\n",
    "print('Confusion Matrix for Classfier:')\n",
    "print(confusion_matrix_y2)\n",
    "\n",
    "print('Classification Report for Classfier:')\n",
    "print(classification_report(y2_test, y2_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
